{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a45564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262200b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a012b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03983712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x71a3582aa120>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_dataloader))\n",
    "plt.imshow(image[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a0dc5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cdc07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe119b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83faf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d8d59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c137d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.311806  [   64/60000]\n",
      "loss: 0.685462  [ 6464/60000]\n",
      "loss: 0.421014  [12864/60000]\n",
      "loss: 0.573526  [19264/60000]\n",
      "loss: 0.487719  [25664/60000]\n",
      "loss: 0.442085  [32064/60000]\n",
      "loss: 0.406853  [38464/60000]\n",
      "loss: 0.548869  [44864/60000]\n",
      "loss: 0.483195  [51264/60000]\n",
      "loss: 0.540701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.434682 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.271866  [   64/60000]\n",
      "loss: 0.363604  [ 6464/60000]\n",
      "loss: 0.280446  [12864/60000]\n",
      "loss: 0.430370  [19264/60000]\n",
      "loss: 0.360791  [25664/60000]\n",
      "loss: 0.361212  [32064/60000]\n",
      "loss: 0.327189  [38464/60000]\n",
      "loss: 0.473269  [44864/60000]\n",
      "loss: 0.411156  [51264/60000]\n",
      "loss: 0.484479  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.393498 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.224913  [   64/60000]\n",
      "loss: 0.326629  [ 6464/60000]\n",
      "loss: 0.224489  [12864/60000]\n",
      "loss: 0.349352  [19264/60000]\n",
      "loss: 0.320522  [25664/60000]\n",
      "loss: 0.338891  [32064/60000]\n",
      "loss: 0.264303  [38464/60000]\n",
      "loss: 0.437786  [44864/60000]\n",
      "loss: 0.345987  [51264/60000]\n",
      "loss: 0.445853  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.369927 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.202418  [   64/60000]\n",
      "loss: 0.291802  [ 6464/60000]\n",
      "loss: 0.202366  [12864/60000]\n",
      "loss: 0.291020  [19264/60000]\n",
      "loss: 0.306913  [25664/60000]\n",
      "loss: 0.344072  [32064/60000]\n",
      "loss: 0.245448  [38464/60000]\n",
      "loss: 0.422325  [44864/60000]\n",
      "loss: 0.302322  [51264/60000]\n",
      "loss: 0.390587  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.356726 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.194267  [   64/60000]\n",
      "loss: 0.262469  [ 6464/60000]\n",
      "loss: 0.207028  [12864/60000]\n",
      "loss: 0.241464  [19264/60000]\n",
      "loss: 0.331418  [25664/60000]\n",
      "loss: 0.327796  [32064/60000]\n",
      "loss: 0.235391  [38464/60000]\n",
      "loss: 0.368867  [44864/60000]\n",
      "loss: 0.289303  [51264/60000]\n",
      "loss: 0.347929  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.346545 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.187757  [   64/60000]\n",
      "loss: 0.223143  [ 6464/60000]\n",
      "loss: 0.193739  [12864/60000]\n",
      "loss: 0.225483  [19264/60000]\n",
      "loss: 0.345520  [25664/60000]\n",
      "loss: 0.292890  [32064/60000]\n",
      "loss: 0.255253  [38464/60000]\n",
      "loss: 0.357580  [44864/60000]\n",
      "loss: 0.272823  [51264/60000]\n",
      "loss: 0.376787  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346663 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.174892  [   64/60000]\n",
      "loss: 0.213059  [ 6464/60000]\n",
      "loss: 0.185762  [12864/60000]\n",
      "loss: 0.197455  [19264/60000]\n",
      "loss: 0.301816  [25664/60000]\n",
      "loss: 0.256182  [32064/60000]\n",
      "loss: 0.226078  [38464/60000]\n",
      "loss: 0.314501  [44864/60000]\n",
      "loss: 0.238331  [51264/60000]\n",
      "loss: 0.295963  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.333614 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.153711  [   64/60000]\n",
      "loss: 0.184469  [ 6464/60000]\n",
      "loss: 0.197857  [12864/60000]\n",
      "loss: 0.196843  [19264/60000]\n",
      "loss: 0.288310  [25664/60000]\n",
      "loss: 0.240926  [32064/60000]\n",
      "loss: 0.201028  [38464/60000]\n",
      "loss: 0.296927  [44864/60000]\n",
      "loss: 0.241532  [51264/60000]\n",
      "loss: 0.278660  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.341642 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.162449  [   64/60000]\n",
      "loss: 0.186960  [ 6464/60000]\n",
      "loss: 0.178485  [12864/60000]\n",
      "loss: 0.184651  [19264/60000]\n",
      "loss: 0.262027  [25664/60000]\n",
      "loss: 0.247718  [32064/60000]\n",
      "loss: 0.179387  [38464/60000]\n",
      "loss: 0.281543  [44864/60000]\n",
      "loss: 0.225135  [51264/60000]\n",
      "loss: 0.201192  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.330314 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.127261  [   64/60000]\n",
      "loss: 0.167131  [ 6464/60000]\n",
      "loss: 0.167687  [12864/60000]\n",
      "loss: 0.162118  [19264/60000]\n",
      "loss: 0.261024  [25664/60000]\n",
      "loss: 0.212869  [32064/60000]\n",
      "loss: 0.260949  [38464/60000]\n",
      "loss: 0.267196  [44864/60000]\n",
      "loss: 0.201081  [51264/60000]\n",
      "loss: 0.256502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.337952 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.119200  [   64/60000]\n",
      "loss: 0.149423  [ 6464/60000]\n",
      "loss: 0.188497  [12864/60000]\n",
      "loss: 0.154793  [19264/60000]\n",
      "loss: 0.232505  [25664/60000]\n",
      "loss: 0.215007  [32064/60000]\n",
      "loss: 0.211987  [38464/60000]\n",
      "loss: 0.250981  [44864/60000]\n",
      "loss: 0.157905  [51264/60000]\n",
      "loss: 0.189877  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.355380 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.112906  [   64/60000]\n",
      "loss: 0.183169  [ 6464/60000]\n",
      "loss: 0.160983  [12864/60000]\n",
      "loss: 0.132346  [19264/60000]\n",
      "loss: 0.247857  [25664/60000]\n",
      "loss: 0.182580  [32064/60000]\n",
      "loss: 0.162373  [38464/60000]\n",
      "loss: 0.258223  [44864/60000]\n",
      "loss: 0.127455  [51264/60000]\n",
      "loss: 0.176506  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.370510 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.102948  [   64/60000]\n",
      "loss: 0.137375  [ 6464/60000]\n",
      "loss: 0.183014  [12864/60000]\n",
      "loss: 0.126223  [19264/60000]\n",
      "loss: 0.234986  [25664/60000]\n",
      "loss: 0.193254  [32064/60000]\n",
      "loss: 0.227949  [38464/60000]\n",
      "loss: 0.255428  [44864/60000]\n",
      "loss: 0.118825  [51264/60000]\n",
      "loss: 0.166306  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.371841 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.123941  [   64/60000]\n",
      "loss: 0.144666  [ 6464/60000]\n",
      "loss: 0.160544  [12864/60000]\n",
      "loss: 0.137716  [19264/60000]\n",
      "loss: 0.178998  [25664/60000]\n",
      "loss: 0.173420  [32064/60000]\n",
      "loss: 0.189162  [38464/60000]\n",
      "loss: 0.228671  [44864/60000]\n",
      "loss: 0.103591  [51264/60000]\n",
      "loss: 0.186374  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.407630 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.095408  [   64/60000]\n",
      "loss: 0.120017  [ 6464/60000]\n",
      "loss: 0.167021  [12864/60000]\n",
      "loss: 0.148525  [19264/60000]\n",
      "loss: 0.195956  [25664/60000]\n",
      "loss: 0.183249  [32064/60000]\n",
      "loss: 0.130494  [38464/60000]\n",
      "loss: 0.209205  [44864/60000]\n",
      "loss: 0.086482  [51264/60000]\n",
      "loss: 0.183413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.409660 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.086654  [   64/60000]\n",
      "loss: 0.117561  [ 6464/60000]\n",
      "loss: 0.130897  [12864/60000]\n",
      "loss: 0.103233  [19264/60000]\n",
      "loss: 0.188135  [25664/60000]\n",
      "loss: 0.211376  [32064/60000]\n",
      "loss: 0.128204  [38464/60000]\n",
      "loss: 0.193460  [44864/60000]\n",
      "loss: 0.087864  [51264/60000]\n",
      "loss: 0.151891  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.437773 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.104929  [   64/60000]\n",
      "loss: 0.126789  [ 6464/60000]\n",
      "loss: 0.162462  [12864/60000]\n",
      "loss: 0.094326  [19264/60000]\n",
      "loss: 0.186364  [25664/60000]\n",
      "loss: 0.221073  [32064/60000]\n",
      "loss: 0.167809  [38464/60000]\n",
      "loss: 0.217176  [44864/60000]\n",
      "loss: 0.052676  [51264/60000]\n",
      "loss: 0.152277  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.444513 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.111274  [   64/60000]\n",
      "loss: 0.100118  [ 6464/60000]\n",
      "loss: 0.140854  [12864/60000]\n",
      "loss: 0.076774  [19264/60000]\n",
      "loss: 0.176687  [25664/60000]\n",
      "loss: 0.226540  [32064/60000]\n",
      "loss: 0.109331  [38464/60000]\n",
      "loss: 0.223356  [44864/60000]\n",
      "loss: 0.069950  [51264/60000]\n",
      "loss: 0.124345  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.423592 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.094191  [   64/60000]\n",
      "loss: 0.090081  [ 6464/60000]\n",
      "loss: 0.126049  [12864/60000]\n",
      "loss: 0.079414  [19264/60000]\n",
      "loss: 0.145956  [25664/60000]\n",
      "loss: 0.209950  [32064/60000]\n",
      "loss: 0.074560  [38464/60000]\n",
      "loss: 0.207544  [44864/60000]\n",
      "loss: 0.094089  [51264/60000]\n",
      "loss: 0.123375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.443519 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.096479  [   64/60000]\n",
      "loss: 0.100073  [ 6464/60000]\n",
      "loss: 0.117339  [12864/60000]\n",
      "loss: 0.081307  [19264/60000]\n",
      "loss: 0.303175  [25664/60000]\n",
      "loss: 0.231348  [32064/60000]\n",
      "loss: 0.077532  [38464/60000]\n",
      "loss: 0.209486  [44864/60000]\n",
      "loss: 0.048568  [51264/60000]\n",
      "loss: 0.131606  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.452860 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.097306  [   64/60000]\n",
      "loss: 0.085591  [ 6464/60000]\n",
      "loss: 0.081373  [12864/60000]\n",
      "loss: 0.076749  [19264/60000]\n",
      "loss: 0.137030  [25664/60000]\n",
      "loss: 0.220876  [32064/60000]\n",
      "loss: 0.078418  [38464/60000]\n",
      "loss: 0.201347  [44864/60000]\n",
      "loss: 0.034139  [51264/60000]\n",
      "loss: 0.126779  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.461202 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.113000  [   64/60000]\n",
      "loss: 0.098443  [ 6464/60000]\n",
      "loss: 0.094131  [12864/60000]\n",
      "loss: 0.067894  [19264/60000]\n",
      "loss: 0.125404  [25664/60000]\n",
      "loss: 0.185357  [32064/60000]\n",
      "loss: 0.080309  [38464/60000]\n",
      "loss: 0.155690  [44864/60000]\n",
      "loss: 0.025187  [51264/60000]\n",
      "loss: 0.143629  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.458666 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.072608  [   64/60000]\n",
      "loss: 0.067427  [ 6464/60000]\n",
      "loss: 0.129207  [12864/60000]\n",
      "loss: 0.058255  [19264/60000]\n",
      "loss: 0.088715  [25664/60000]\n",
      "loss: 0.130604  [32064/60000]\n",
      "loss: 0.147113  [38464/60000]\n",
      "loss: 0.188326  [44864/60000]\n",
      "loss: 0.021424  [51264/60000]\n",
      "loss: 0.146197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.466519 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.089842  [   64/60000]\n",
      "loss: 0.117898  [ 6464/60000]\n",
      "loss: 0.122394  [12864/60000]\n",
      "loss: 0.076815  [19264/60000]\n",
      "loss: 0.084953  [25664/60000]\n",
      "loss: 0.159152  [32064/60000]\n",
      "loss: 0.066041  [38464/60000]\n",
      "loss: 0.138551  [44864/60000]\n",
      "loss: 0.017031  [51264/60000]\n",
      "loss: 0.117767  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.474683 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.063752  [   64/60000]\n",
      "loss: 0.090792  [ 6464/60000]\n",
      "loss: 0.119162  [12864/60000]\n",
      "loss: 0.061038  [19264/60000]\n",
      "loss: 0.077441  [25664/60000]\n",
      "loss: 0.144961  [32064/60000]\n",
      "loss: 0.102225  [38464/60000]\n",
      "loss: 0.105955  [44864/60000]\n",
      "loss: 0.068792  [51264/60000]\n",
      "loss: 0.163433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.489772 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.138357  [   64/60000]\n",
      "loss: 0.087588  [ 6464/60000]\n",
      "loss: 0.127869  [12864/60000]\n",
      "loss: 0.092419  [19264/60000]\n",
      "loss: 0.166627  [25664/60000]\n",
      "loss: 0.197783  [32064/60000]\n",
      "loss: 0.077324  [38464/60000]\n",
      "loss: 0.091678  [44864/60000]\n",
      "loss: 0.042204  [51264/60000]\n",
      "loss: 0.144246  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.520368 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.105516  [   64/60000]\n",
      "loss: 0.062106  [ 6464/60000]\n",
      "loss: 0.100614  [12864/60000]\n",
      "loss: 0.104771  [19264/60000]\n",
      "loss: 0.133426  [25664/60000]\n",
      "loss: 0.175911  [32064/60000]\n",
      "loss: 0.062249  [38464/60000]\n",
      "loss: 0.098126  [44864/60000]\n",
      "loss: 0.089210  [51264/60000]\n",
      "loss: 0.085989  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.525453 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.090535  [   64/60000]\n",
      "loss: 0.067860  [ 6464/60000]\n",
      "loss: 0.096475  [12864/60000]\n",
      "loss: 0.055299  [19264/60000]\n",
      "loss: 0.078858  [25664/60000]\n",
      "loss: 0.163706  [32064/60000]\n",
      "loss: 0.103641  [38464/60000]\n",
      "loss: 0.101190  [44864/60000]\n",
      "loss: 0.071807  [51264/60000]\n",
      "loss: 0.063989  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.564200 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.096766  [   64/60000]\n",
      "loss: 0.052976  [ 6464/60000]\n",
      "loss: 0.116882  [12864/60000]\n",
      "loss: 0.072567  [19264/60000]\n",
      "loss: 0.071452  [25664/60000]\n",
      "loss: 0.128766  [32064/60000]\n",
      "loss: 0.082944  [38464/60000]\n",
      "loss: 0.041244  [44864/60000]\n",
      "loss: 0.049335  [51264/60000]\n",
      "loss: 0.061737  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.592546 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.090619  [   64/60000]\n",
      "loss: 0.029558  [ 6464/60000]\n",
      "loss: 0.119787  [12864/60000]\n",
      "loss: 0.044732  [19264/60000]\n",
      "loss: 0.073664  [25664/60000]\n",
      "loss: 0.137816  [32064/60000]\n",
      "loss: 0.061627  [38464/60000]\n",
      "loss: 0.127243  [44864/60000]\n",
      "loss: 0.072179  [51264/60000]\n",
      "loss: 0.079661  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.605265 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58d377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"model/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc433d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model/model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b09126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
